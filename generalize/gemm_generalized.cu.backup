#include <algorithm>
#include <cmath>
#include <cstring>
#include <fstream>
#include <iomanip>
#include <iostream>
#include <memory>
#include <sstream>
#include <string>
#include <vector>

#include "cutlass/cutlass.h"
#include "cutlass/gemm/device/gemm.h"
#include "cutlass/gemm/device/gemm_splitk_parallel.h"
#include <cuda_profiler_api.h>
#include <cuda_runtime.h>

// =========================================================================
// 0. Basic Definitions & Utils
// =========================================================================
#define CUDA_CHECK(status)                                                     \
  {                                                                            \
    if (status != cudaSuccess) {                                               \
      std::cerr << "CUDA Error: " << cudaGetErrorString(status) << std::endl;  \
      exit(1);                                                                 \
    }                                                                          \
  }

using ArchTag = cutlass::arch::Sm80;
using OpClass = cutlass::arch::OpClassTensorOp;

struct DeviceSpecs {
  std::string name;
  double peak_tflops; // TFLOPS
  double peak_bw;     // GB/s
  double clock_rate_khz;
  int num_sms;

  static DeviceSpecs &get() {
    static DeviceSpecs instance;
    static bool init = false;
    if (!init) {
      int dev;
      cudaGetDevice(&dev);
      cudaDeviceProp p;
      cudaGetDeviceProperties(&p, dev);
      instance.name = p.name;
      instance.clock_rate_khz = (double)p.clockRate;
      instance.num_sms = p.multiProcessorCount;

      std::string name_str = p.name;
      // Rough estimates for peak FP16 Tensor Core TFLOPS
      if (name_str.find("H100") != std::string::npos) {
        instance.peak_tflops = 989.0;
        instance.peak_bw = 3350.0;
      } else if (name_str.find("A100") != std::string::npos) {
        instance.peak_tflops = 312.0;
        instance.peak_bw = 1555.0;
      } else if (name_str.find("V100") != std::string::npos) {
        instance.peak_tflops = 125.0;
        instance.peak_bw = 900.0;
      } else if (name_str.find("4090") != std::string::npos) {
        instance.peak_tflops = 330.0;
        instance.peak_bw = 1008.0;
      } else {
        instance.peak_tflops = 100.0;
        instance.peak_bw = 900.0;
      }
      init = true;
    }
    return instance;
  }
};

enum class RunStatus { Success, SMemExceeded, Unsupported, RuntimeError };

struct RunResult {
  std::string name;
  std::string dtype;
  int stage;
  RunStatus status;
  double time_ms;
  double tflops;
  long long cycles;
  double mfu;
  double hbm_eff;

  int grid_size;
  int active_blocks;
  double grid_util;
  int split_k;
};

struct CaseResult {
  int m, n, k;
  std::string dtype;
  RunResult best_run;
  std::vector<RunResult> all_runs;
};

// =========================================================================
// 1. Argument Parser
// =========================================================================
struct ArgParser {
  static std::vector<int> parse(const std::string &input) {
    std::vector<int> values;
    if (input.front() == '[' && input.back() == ']') {
      std::string content = input.substr(1, input.size() - 2);
      size_t colon = content.find(':');
      if (colon == std::string::npos) {
        std::cerr << "Invalid range format. Use [start:end]" << std::endl;
        exit(1);
      }
      int start = std::stoi(content.substr(0, colon));
      int end = std::stoi(content.substr(colon + 1));

      for (int i = start; i <= end; i *= 2) {
        values.push_back(i);
      }
    } else {
      values.push_back(std::stoi(input));
    }
    return values;
  }

  static std::vector<std::string> parse_dtypes(const std::string &input) {
    std::vector<std::string> dtypes;
    std::stringstream ss(input);
    std::string item;
    while (std::getline(ss, item, ',')) {
      dtypes.push_back(item);
    }
    return dtypes;
  }

  static std::vector<int> parse_linear(const std::string &input) {
    std::vector<int> values;
    if (input.front() == '[' && input.back() == ']') {
      std::string content = input.substr(1, input.size() - 2);
      size_t sep = content.find(',');
      if (sep == std::string::npos)
        sep = content.find(':');
      if (sep != std::string::npos) {
        int start = std::stoi(content.substr(0, sep));
        int end = std::stoi(content.substr(sep + 1));
        for (int i = start; i <= end; i++)
          values.push_back(i);
      } else {
        values.push_back(std::stoi(content));
      }
    } else {
      std::stringstream ss(input);
      std::string item;
      while (std::getline(ss, item, ',')) {
        values.push_back(std::stoi(item));
      }
    }
    return values;
  }
};

// =========================================================================
// 2. CUTLASS Runner Interface
// =========================================================================
struct GemmRunner {
  virtual ~GemmRunner() {}
  virtual std::string name() const = 0;
  virtual RunResult run(int M, int N, int K, void *d_A, void *d_B, void *d_C,
                        bool profile) = 0;
};

struct DeviceProps {
  int max_smem;
  static const DeviceProps &get() {
    static DeviceProps instance;
    static bool init = false;
    if (!init) {
      int dev;
      cudaGetDevice(&dev);
      cudaDeviceProp p;
      cudaGetDeviceProperties(&p, dev);
      instance.max_smem = p.sharedMemPerBlockOptin;
      init = true;
    }
    return instance;
  }
};

// =========================================================================
// 3. Gemm Implementations
// =========================================================================

// Standard GEMM
template <typename ElementA, typename LayoutA, typename ElementB,
          typename LayoutB, typename ElementC, typename LayoutC,
          typename ElementAccumulator, typename ThreadblockShape,
          typename WarpShape, typename InstructionShape, int kStages,
          int kAlignmentA, int kAlignmentB, bool SplitKSerial = false,
          typename Operator = cutlass::arch::OpMultiplyAdd>
struct GemmImpl : public GemmRunner {
  // Revert to vector width 1 for standard GEMM
  // static constexpr int kEpilogueElementsPerAccess =
  //     128 / cutlass::sizeof_bits<ElementC>::value;

  using EpilogueOp = cutlass::epilogue::thread::LinearCombination<
      ElementC, 1, ElementAccumulator, ElementAccumulator>;

  using GemmHandle = cutlass::gemm::device::Gemm<
      ElementA, LayoutA, ElementB, LayoutB, ElementC, LayoutC,
      ElementAccumulator, OpClass, ArchTag, ThreadblockShape, WarpShape,
      InstructionShape, EpilogueOp,
      cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>, kStages,
      kAlignmentA, kAlignmentB, SplitKSerial, Operator>;

  using DeviceKernel = typename GemmHandle::GemmKernel;

  std::string name() const override {
    std::stringstream ss;
    ss << ThreadblockShape::kM << "x" << ThreadblockShape::kN << "x"
       << ThreadblockShape::kK << "_S" << kStages;
    return ss.str();
  }

  RunResult run(int M, int N, int K, void *d_A, void *d_B, void *d_C,
                bool profile) override {
    RunResult res;
    res.name = name();
    res.stage = kStages;
    res.split_k = 1;
    res.time_ms = 0;
    res.tflops = 0;
    res.cycles = 0;
    res.mfu = 0;
    res.hbm_eff = 0;
    res.grid_size = 0;
    res.active_blocks = 0;
    res.grid_util = 0;

    int smem = sizeof(typename DeviceKernel::SharedStorage);
    if (smem > DeviceProps::get().max_smem) {
      res.status = RunStatus::SMemExceeded;
      return res;
    }

    int lda = (std::is_same<LayoutA, cutlass::layout::RowMajor>::value) ? K : M;
    int ldb = (std::is_same<LayoutB, cutlass::layout::RowMajor>::value) ? N : K;
    int ldc = (std::is_same<LayoutC, cutlass::layout::RowMajor>::value) ? N : M;

    typename GemmHandle::Arguments args(
        {M, N, K}, {static_cast<ElementA *>(d_A), lda},
        {static_cast<ElementB *>(d_B), ldb},
        {static_cast<ElementC *>(d_C), ldc},
        {static_cast<ElementC *>(d_C), ldc},
        {ElementAccumulator(1.0), ElementAccumulator(0.0)});
    GemmHandle gemm;

    if (gemm.can_implement(args) != cutlass::Status::kSuccess) {
      res.status = RunStatus::Unsupported;
      return res;
    }

    if (smem >= (48 << 10)) {
      if (cudaFuncSetAttribute(cutlass::Kernel<DeviceKernel>,
                               cudaFuncAttributeMaxDynamicSharedMemorySize,
                               smem) != cudaSuccess) {
        res.status = RunStatus::SMemExceeded;
        return res;
      }
    }

    int max_active_blocks = 0;
    cudaOccupancyMaxActiveBlocksPerMultiprocessor(
        &max_active_blocks, cutlass::Kernel<DeviceKernel>,
        DeviceKernel::kThreadCount, smem);
    res.active_blocks = max_active_blocks;

    int grid_m = (M + ThreadblockShape::kM - 1) / ThreadblockShape::kM;
    int grid_n = (N + ThreadblockShape::kN - 1) / ThreadblockShape::kN;
    res.grid_size = grid_m * grid_n;

    const auto &specs = DeviceSpecs::get();
    res.grid_util = (double)res.grid_size / (double)specs.num_sms;

    size_t ws_size = GemmHandle::get_workspace_size(args);
    void *ws = nullptr;
    if (ws_size)
      cudaMalloc(&ws, ws_size);

    if (gemm.initialize(args, ws) != cutlass::Status::kSuccess) {
      if (ws)
        cudaFree(ws);
      res.status = RunStatus::RuntimeError;
      return res;
    }

    gemm(); // Warmup
    cudaEvent_t start, stop;
    cudaEventCreate(&start);
    cudaEventCreate(&stop);

    if (profile)
      cudaProfilerStart();

    cudaEventRecord(start);
    for (int i = 0; i < 5; i++)
      gemm();
    cudaEventRecord(stop);
    cudaEventSynchronize(stop);

    if (profile)
      cudaProfilerStop();

    float ms = 0;
    cudaEventElapsedTime(&ms, start, stop);
    res.time_ms = ms / 5.0f;

    double gflops = (2.0 * M * N * K) * 1e-9;
    res.tflops = gflops / res.time_ms;
    res.cycles = (long long)(res.time_ms * specs.clock_rate_khz);
    res.mfu = (res.tflops / specs.peak_tflops) * 100.0;

    double bytes =
        (double)(M * K * sizeof(ElementA) + K * N * sizeof(ElementB) +
                 M * N * sizeof(ElementC));
    double gb = bytes * 1e-9;
    double bw = gb / (res.time_ms * 1e-3);
    res.hbm_eff = (bw / specs.peak_bw) * 100.0;

    res.status = RunStatus::Success;

    if (ws)
      cudaFree(ws);
    cudaEventDestroy(start);
    cudaEventDestroy(stop);
    return res;
  }
};

// Split-K Parallel GEMM
template <typename ElementA, typename LayoutA, typename ElementB,
          typename LayoutB, typename ElementC, typename LayoutC,
          typename ElementAccumulator, typename ThreadblockShape,
          typename WarpShape, typename InstructionShape, int kStages,
          int kSplitK, int kAlignmentA, int kAlignmentB,
          typename Operator = cutlass::arch::OpMultiplyAdd>
struct GemmSplitKImpl : public GemmRunner {
  static constexpr int kEpilogueElementsPerAccess =
      128 / cutlass::sizeof_bits<ElementC>::value;

  using EpilogueOp = cutlass::epilogue::thread::LinearCombination<
      ElementC, kEpilogueElementsPerAccess, ElementAccumulator,
      ElementAccumulator>;

  using GemmHandle = cutlass::gemm::device::GemmSplitKParallel<
      ElementA, LayoutA, ElementB, LayoutB, ElementC, LayoutC,
      ElementAccumulator, OpClass, ArchTag, ThreadblockShape, WarpShape,
      InstructionShape, EpilogueOp,
      cutlass::epilogue::thread::Convert<
          ElementAccumulator, kEpilogueElementsPerAccess, ElementAccumulator>,
      cutlass::reduction::thread::ReduceAdd<
          ElementAccumulator, ElementAccumulator, kEpilogueElementsPerAccess>,
      cutlass::gemm::threadblock::GemmSplitKHorizontalThreadblockSwizzle,
      kStages, kAlignmentA, kAlignmentB, Operator>;

  using DeviceKernel = typename GemmHandle::GemmKernel;

  std::string name() const override {
    std::stringstream ss;
    ss << ThreadblockShape::kM << "x" << ThreadblockShape::kN << "x"
       << ThreadblockShape::kK << "_S" << kStages << "_SK" << kSplitK;
    return ss.str();
  }

  RunResult run(int M, int N, int K, void *d_A, void *d_B, void *d_C,
                bool profile) override {
    RunResult res;
    res.name = name();
    res.stage = kStages;
    res.split_k = kSplitK;
    res.time_ms = 0;
    res.tflops = 0;
    res.cycles = 0;
    res.mfu = 0;
    res.hbm_eff = 0;
    res.grid_size = 0;
    res.active_blocks = 0;
    res.grid_util = 0;

    int smem = sizeof(typename DeviceKernel::SharedStorage);
    if (smem > DeviceProps::get().max_smem) {
      res.status = RunStatus::SMemExceeded;
      return res;
    }

    int lda = (std::is_same<LayoutA, cutlass::layout::RowMajor>::value) ? K : M;
    int ldb = (std::is_same<LayoutB, cutlass::layout::RowMajor>::value) ? N : K;
    int ldc = (std::is_same<LayoutC, cutlass::layout::RowMajor>::value) ? N : M;

    typename GemmHandle::Arguments args(
        {M, N, K}, {static_cast<ElementA *>(d_A), lda},
        {static_cast<ElementB *>(d_B), ldb},
        {static_cast<ElementC *>(d_C), ldc},
        {static_cast<ElementC *>(d_C), ldc},
        {ElementAccumulator(1.0), ElementAccumulator(0.0)}, kSplitK);
    GemmHandle gemm;

    if (gemm.can_implement(args) != cutlass::Status::kSuccess) {
      res.status = RunStatus::Unsupported;
      return res;
    }

    if (smem >= (48 << 10)) {
      if (cudaFuncSetAttribute(cutlass::Kernel<DeviceKernel>,
                               cudaFuncAttributeMaxDynamicSharedMemorySize,
                               smem) != cudaSuccess) {
        res.status = RunStatus::SMemExceeded;
        return res;
      }
    }

    int max_active_blocks = 0;
    cudaOccupancyMaxActiveBlocksPerMultiprocessor(
        &max_active_blocks, cutlass::Kernel<DeviceKernel>,
        DeviceKernel::kThreadCount, smem);
    res.active_blocks = max_active_blocks;

    int grid_m = (M + ThreadblockShape::kM - 1) / ThreadblockShape::kM;
    int grid_n = (N + ThreadblockShape::kN - 1) / ThreadblockShape::kN;
    res.grid_size = grid_m * grid_n * kSplitK;

    const auto &specs = DeviceSpecs::get();
    res.grid_util = (double)res.grid_size / (double)specs.num_sms;

    size_t ws_size = GemmHandle::get_workspace_size(args);
    void *ws = nullptr;
    if (ws_size)
      cudaMalloc(&ws, ws_size);

    if (gemm.initialize(args, ws) != cutlass::Status::kSuccess) {
      if (ws)
        cudaFree(ws);
      res.status = RunStatus::RuntimeError;
      return res;
    }

    gemm(); // Warmup
    cudaEvent_t start, stop;
    cudaEventCreate(&start);
    cudaEventCreate(&stop);

    if (profile)
      cudaProfilerStart();

    cudaEventRecord(start);
    for (int i = 0; i < 5; i++)
      gemm();
    cudaEventRecord(stop);
    cudaEventSynchronize(stop);

    if (profile)
      cudaProfilerStop();

    float ms = 0;
    cudaEventElapsedTime(&ms, start, stop);
    res.time_ms = ms / 5.0f;

    double gflops = (2.0 * M * N * K) * 1e-9;
    res.tflops = gflops / res.time_ms;
    res.cycles = (long long)(res.time_ms * specs.clock_rate_khz);
    res.mfu = (res.tflops / specs.peak_tflops) * 100.0;

    double bytes =
        (double)(M * K * sizeof(ElementA) + K * N * sizeof(ElementB) +
                 M * N * sizeof(ElementC));
    double gb = bytes * 1e-9;
    double bw = gb / (res.time_ms * 1e-3);
    res.hbm_eff = (bw / specs.peak_bw) * 100.0;

    res.status = RunStatus::Success;

    if (ws)
      cudaFree(ws);
    cudaEventDestroy(start);
    cudaEventDestroy(stop);
    return res;
  }
};

// =========================================================================
// 4. Sweeper Class
// =========================================================================
class GemmSweeper {
  std::vector<std::shared_ptr<GemmRunner>> configs;
  std::string current_dtype;
  std::vector<int> enabled_stages;

public:
  GemmSweeper() { enabled_stages = {2, 3, 4}; }

  void set_stages(const std::vector<int> &stages) { enabled_stages = stages; }

  bool is_stage_enabled(int s) {
    for (int es : enabled_stages)
      if (es == s)
        return true;
    return false;
  }

  void set_dtype(std::string dtype) {
    current_dtype = dtype;
    configs.clear();
    if (dtype == "fp32") {
      setup_fp32();
    } else if (dtype == "fp16") {
      setup_fp16();
    } else if (dtype == "bf16") {
      setup_bf16();
    } else if (dtype == "int8") {
      setup_int8();
    } else if (dtype == "tf32") {
      setup_tf32();
    } else {
      std::cerr << "Unknown dtype: " << dtype << std::endl;
      exit(1);
    }
  }

  void setup_tf32() {
    using ElementA = cutlass::tfloat32_t;
    using ElementB = cutlass::tfloat32_t;
    using ElementC = float;
    using ElementAccum = float;
    using LayoutA = cutlass::layout::RowMajor;
    using LayoutB = cutlass::layout::RowMajor;
    using LayoutC = cutlass::layout::RowMajor;
    using Inst = cutlass::gemm::GemmShape<16, 8, 8>;

#define REG_TF32(Tm, Tn, Wm, Wn, Stg)                                          \
  if (is_stage_enabled(Stg))                                                   \
  configs.push_back(                                                           \
      std::make_shared<                                                        \
          GemmImpl<ElementA, LayoutA, ElementB, LayoutB, ElementC, LayoutC,    \
                   ElementAccum, cutlass::gemm::GemmShape<Tm, Tn, 64>,         \
                   cutlass::gemm::GemmShape<Wm, Wn, 64>, Inst, Stg, 4, 4,      \
                   false, cutlass::arch::OpMultiplyAdd>>())

    // K is fixed at 64 for all configurations
    REG_TF32(256, 256, 64, 64, 2);
    REG_TF32(256, 128, 64, 64, 2);
    REG_TF32(128, 256, 64, 64, 2);
    REG_TF32(128, 128, 64, 64, 2);
    REG_TF32(64, 64, 32, 32, 2);

    REG_TF32(256, 256, 64, 64, 3);
    REG_TF32(256, 128, 64, 64, 3);
    REG_TF32(128, 256, 64, 64, 3);
    REG_TF32(128, 128, 64, 64, 3);
    REG_TF32(64, 64, 32, 32, 3);

    REG_TF32(256, 256, 64, 64, 4);
    REG_TF32(256, 128, 64, 64, 4);
    REG_TF32(128, 256, 64, 64, 4);
    REG_TF32(128, 128, 64, 64, 4);
    REG_TF32(64, 64, 32, 32, 4);

#undef REG_TF32
  }

  void setup_fp32() {
    using ElementA = float;
    using ElementB = float;
    using ElementC = float;
    using ElementAccum = float;
    using LayoutA = cutlass::layout::RowMajor;
    using LayoutB = cutlass::layout::RowMajor;
    using LayoutC = cutlass::layout::RowMajor;
    using Inst = cutlass::gemm::GemmShape<16, 8, 8>;

#define REG_FP32(Tm, Tn, Wm, Wn, Stg)                                          \
  if (is_stage_enabled(Stg))                                                   \
  configs.push_back(                                                           \
      std::make_shared<                                                        \
          GemmImpl<ElementA, LayoutA, ElementB, LayoutB, ElementC, LayoutC,    \
                   ElementAccum, cutlass::gemm::GemmShape<Tm, Tn, 64>,         \
                   cutlass::gemm::GemmShape<Wm, Wn, 64>, Inst, Stg, 4, 4,      \
                   false, cutlass::arch::OpMultiplyAdd>>())

    // K is fixed at 64 for all configurations
    REG_FP32(256, 256, 64, 64, 2);
    REG_FP32(256, 128, 64, 64, 2);
    REG_FP32(128, 256, 64, 64, 2);
    REG_FP32(128, 128, 64, 64, 2);
    REG_FP32(64, 64, 32, 32, 2);

    REG_FP32(256, 256, 64, 64, 3);
    REG_FP32(256, 128, 64, 64, 3);
    REG_FP32(128, 256, 64, 64, 3);
    REG_FP32(128, 128, 64, 64, 3);
    REG_FP32(64, 64, 32, 32, 3);

    REG_FP32(256, 256, 64, 64, 4);
    REG_FP32(256, 128, 64, 64, 4);
    REG_FP32(128, 256, 64, 64, 4);
    REG_FP32(128, 128, 64, 64, 4);
    REG_FP32(64, 64, 32, 32, 4);

#undef REG_FP32
  }

  void setup_fp16() {
    using ElementA = cutlass::half_t;
    using ElementB = cutlass::half_t;
    using ElementC = cutlass::half_t;
    using ElementAccum = float;
    using LayoutA = cutlass::layout::RowMajor;
    using LayoutB = cutlass::layout::RowMajor;
    using LayoutC = cutlass::layout::RowMajor;
    using Inst = cutlass::gemm::GemmShape<16, 8, 16>;

#define REG_FP16(Tm, Tn, Wm, Wn, Stg)                                          \
  if (is_stage_enabled(Stg))                                                   \
  \\\n configs.push_back(                                                      \
      std::make_shared<                                                        \
          GemmImpl<ElementA, LayoutA, ElementB, LayoutB, ElementC, LayoutC,    \
                   ElementAccum, cutlass::gemm::GemmShape<Tm, Tn, 64>,         \
                   cutlass::gemm::GemmShape<Wm, Wn, 64>, Inst, Stg, 8, 8,      \
                   false, cutlass::arch::OpMultiplyAdd>>())

    // K is fixed at 64 for all configurations
    REG_FP16(256, 256, 64, 64, 2);
    REG_FP16(256, 128, 64, 64, 2);
    REG_FP16(128, 256, 64, 64, 2);
    REG_FP16(128, 128, 64, 64, 2);
    REG_FP16(64, 64, 32, 32, 2);

    REG_FP16(256, 256, 64, 64, 3);
    REG_FP16(256, 128, 64, 64, 3);
    REG_FP16(128, 256, 64, 64, 3);
    REG_FP16(128, 128, 64, 64, 3);
    REG_FP16(64, 64, 32, 32, 3);

    REG_FP16(256, 256, 64, 64, 4);
    REG_FP16(256, 128, 64, 64, 4);
    REG_FP16(128, 256, 64, 64, 4);
    REG_FP16(128, 128, 64, 64, 4);
    REG_FP16(64, 64, 32, 32, 4);

#undef REG_FP16
  }

  void setup_bf16() {
    using ElementA = cutlass::bfloat16_t;
    using ElementB = cutlass::bfloat16_t;
    using ElementC = cutlass::bfloat16_t;
    using ElementAccum = float;
    using LayoutA = cutlass::layout::RowMajor;
    using LayoutB = cutlass::layout::RowMajor;
    using LayoutC = cutlass::layout::RowMajor;
    using Inst = cutlass::gemm::GemmShape<16, 8, 16>;

#define REG_BF16(Tm, Tn, Wm, Wn, Stg)                                          \
  if (is_stage_enabled(Stg))                                                   \
  configs.push_back(                                                           \
      std::make_shared<                                                        \
          GemmImpl<ElementA, LayoutA, ElementB, LayoutB, ElementC, LayoutC,    \
                   ElementAccum, cutlass::gemm::GemmShape<Tm, Tn, 64>,         \
                   cutlass::gemm::GemmShape<Wm, Wn, 64>, Inst, Stg, 8, 8,      \
                   false, cutlass::arch::OpMultiplyAdd>>())

    // K is fixed at 64 for all configurations
    REG_BF16(256, 256, 64, 64, 2);
    REG_BF16(256, 128, 64, 64, 2);
    REG_BF16(128, 256, 64, 64, 2);
    REG_BF16(128, 128, 64, 64, 2);
    REG_BF16(64, 64, 32, 32, 2);

    REG_BF16(256, 256, 64, 64, 3);
    REG_BF16(256, 128, 64, 64, 3);
    REG_BF16(128, 256, 64, 64, 3);
    REG_BF16(128, 128, 64, 64, 3);
    REG_BF16(64, 64, 32, 32, 3);

    REG_BF16(256, 256, 64, 64, 4);
    REG_BF16(256, 128, 64, 64, 4);
    REG_BF16(128, 256, 64, 64, 4);
    REG_BF16(128, 128, 64, 64, 4);
    REG_BF16(64, 64, 32, 32, 4);

#undef REG_BF16
  }

  void setup_int8() {
    using ElementA = int8_t;
    using ElementB = int8_t;
    using ElementC = int32_t;
    using ElementAccum = int32_t;
    using LayoutA = cutlass::layout::RowMajor;
    using LayoutB = cutlass::layout::ColumnMajor;
    using LayoutC = cutlass::layout::RowMajor;
    using Inst = cutlass::gemm::GemmShape<16, 8, 32>;

#define REG_INT8(Tm, Tn, Wm, Wn, Stg)                                          \
  if (is_stage_enabled(Stg))                                                   \
  configs.push_back(                                                           \
      std::make_shared<                                                        \
          GemmImpl<ElementA, LayoutA, ElementB, LayoutB, ElementC, LayoutC,    \
                   ElementAccum, cutlass::gemm::GemmShape<Tm, Tn, 64>,         \
                   cutlass::gemm::GemmShape<Wm, Wn, 64>, Inst, Stg, 16, 16,    \
                   false, cutlass::arch::OpMultiplyAddSaturate>>())

    // K is fixed at 64 for all configurations
    REG_INT8(256, 256, 64, 64, 2);
    REG_INT8(256, 128, 64, 64, 2);
    REG_INT8(128, 256, 64, 64, 2);
    REG_INT8(128, 128, 64, 64, 2);

    REG_INT8(256, 256, 64, 64, 3);
    REG_INT8(256, 128, 64, 64, 3);
    REG_INT8(128, 256, 64, 64, 3);
    REG_INT8(128, 128, 64, 64, 3);

    REG_INT8(256, 256, 64, 64, 4);
    REG_INT8(256, 128, 64, 64, 4);
    REG_INT8(128, 256, 64, 64, 4);
    REG_INT8(128, 128, 64, 64, 4);

#undef REG_INT8
  }

  CaseResult find_best(int M, int N, int K, void *d_A, void *d_B, void *d_C,
                       bool profile) {
    CaseResult result;
    result.m = M;
    result.n = N;
    result.k = K;
    result.dtype = current_dtype;
    result.best_run.tflops = -1.0;

    for (auto &cfg : configs) {
      RunResult res = cfg->run(M, N, K, d_A, d_B, d_C, profile);
      res.dtype = current_dtype;
      result.all_runs.push_back(res);

      if (res.status == RunStatus::Success &&
          res.tflops > result.best_run.tflops) {
        result.best_run = res;
      }
    }
    return result;
  }
};

// =========================================================================
// 5. Main
// =========================================================================
int main(int argc, char **argv) {
  std::string m_str, n_str, k_str;
  bool profile = false;
  std::string csv_path = "gemm_results.csv";
  std::vector<std::string> dtypes = {"fp32"};
  std::vector<int> stages = {2, 3, 4};

  double override_peak_tflops = 0.0;
  double override_peak_bw = 0.0;

  for (int i = 1; i < argc; i++) {
    if (strcmp(argv[i], "--M") == 0 && i + 1 < argc)
      m_str = argv[++i];
    else if (strcmp(argv[i], "--N") == 0 && i + 1 < argc)
      n_str = argv[++i];
    else if (strcmp(argv[i], "--K") == 0 && i + 1 < argc)
      k_str = argv[++i];
    else if (strcmp(argv[i], "--profile") == 0)
      profile = true;
    else if (strcmp(argv[i], "--csv") == 0 && i + 1 < argc)
      csv_path = argv[++i];
    else if (strcmp(argv[i], "--dtype") == 0 && i + 1 < argc)
      dtypes = ArgParser::parse_dtypes(argv[++i]);
    else if (strcmp(argv[i], "--stage") == 0 && i + 1 < argc)
      stages = ArgParser::parse_linear(argv[++i]);
    else if (strcmp(argv[i], "--peak_tflops") == 0 && i + 1 < argc)
      override_peak_tflops = std::stod(argv[++i]);
    else if (strcmp(argv[i], "--peak_bw") == 0 && i + 1 < argc)
      override_peak_bw = std::stod(argv[++i]);
  }

  if (m_str.empty() || n_str.empty() || k_str.empty()) {
    std::cerr << "Usage: " << argv[0]
              << " --M [start:end] --N [start:end] --K val [--dtype "
                 "fp32,fp16,bf16,int8] [--profile] [--csv path]"
              << std::endl;
    return 1;
  }

  if (override_peak_tflops > 0)
    DeviceSpecs::get().peak_tflops = override_peak_tflops;
  if (override_peak_bw > 0)
    DeviceSpecs::get().peak_bw = override_peak_bw;

  const auto &specs = DeviceSpecs::get();
  std::cout << ">>> Device: " << specs.name << " (" << specs.num_sms << " SMs)"
            << std::endl;
  std::cout << ">>> Peak TFLOPS: " << specs.peak_tflops
            << " | Peak BW: " << specs.peak_bw << " GB/s" << std::endl;
  std::cout << ">>> Data Types: ";
  for (const auto &d : dtypes)
    std::cout << d << " ";
  std::cout << std::endl;

  auto ms = ArgParser::parse(m_str);
  auto ns = ArgParser::parse(n_str);
  auto ks = ArgParser::parse(k_str);

  int max_m = *std::max_element(ms.begin(), ms.end());
  int max_n = *std::max_element(ns.begin(), ns.end());
  int max_k = *std::max_element(ks.begin(), ks.end());

  // Determine max element size for allocation
  size_t max_element_size_a = 4;
  size_t max_element_size_b = 4;
  size_t max_element_size_c = 4;

  for (const auto &dtype : dtypes) {
    if (dtype == "fp16" || dtype == "bf16") {
      // 2 bytes
    } else if (dtype == "int8") {
      // 1 byte, but we allocate max so 4 is fine
    }
    // fp32 is 4 bytes, so default 4 covers all.
  }

  size_t bytes_A = (size_t)max_m * max_k * max_element_size_a;
  size_t bytes_B = (size_t)max_k * max_n * max_element_size_b;
  size_t bytes_C = (size_t)max_m * max_n * max_element_size_c;

  void *d_A, *d_B, *d_C;
  CUDA_CHECK(cudaMalloc(&d_A, bytes_A));
  CUDA_CHECK(cudaMalloc(&d_B, bytes_B));
  CUDA_CHECK(cudaMalloc(&d_C, bytes_C));
  cudaMemset(d_A, 0, bytes_A);
  cudaMemset(d_B, 0, bytes_B);
  cudaMemset(d_C, 0, bytes_C);

  GemmSweeper sweeper;
  sweeper.set_stages(stages);
  std::vector<CaseResult> summary;

  std::cout << ">>> Starting Scan... Output CSV: " << csv_path << std::endl;

  // CSV Header
  std::ofstream csv(csv_path);
  csv << "dtype,M,N,K,Tile,Stage,Status,Time_ms,Cycles,TFLOPS,MFU,HBM_Eff,"
         "GridSize,"
         "ActiveBlocksPerSM,Waves,SplitK\n";
  csv.close(); // Close to append later or keep open? Better to append in loop.

  for (const auto &dtype : dtypes) {
    sweeper.set_dtype(dtype);

    std::cout << "\n>>> Benchmarking " << dtype << "..." << std::endl;
    std::cout << std::left << std::setw(8) << "M" << std::setw(8) << "N"
              << std::setw(8) << "K"
              << "| " << std::setw(20) << "Best Tile"
              << " | " << std::setw(8) << "TFLOPS"
              << " | " << std::setw(8) << "MFU(%)"
              << " | " << std::setw(8) << "Waves" << std::endl;
    std::cout
        << "---------------------------------------------------------------"
           "---------"
        << std::endl;

    for (int m : ms) {
      for (int n : ns) {
        for (int k : ks) {
          CaseResult res = sweeper.find_best(m, n, k, d_A, d_B, d_C, profile);
          summary.push_back(res);

          std::cout << std::left << std::setw(8) << m << std::setw(8) << n
                    << std::setw(8) << k << "| " << std::setw(20)
                    << res.best_run.name << " | " << std::fixed
                    << std::setprecision(2) << res.best_run.tflops << " | "
                    << std::setw(8) << res.best_run.mfu << " | "
                    << res.best_run.grid_util << std::endl;

          // Append to CSV immediately
          std::ofstream csv_append(csv_path, std::ios::app);
          for (const auto &run : res.all_runs) {
            csv_append << run.dtype << "," << m << "," << n << "," << k << ","
                       << run.name << "," << run.stage << "," << (int)run.status
                       << "," << run.time_ms << "," << run.cycles << ","
                       << run.tflops << "," << run.mfu << "," << run.hbm_eff
                       << "," << run.grid_size << "," << run.active_blocks
                       << "," << run.grid_util << "," << run.split_k << "\n";
          }
          csv_append.close();
        }
      }
    }
  }

  // Final Report
  std::cout << "\n============================================================="
               "====================================================="
            << std::endl;
  std::cout << "                                        FINAL SUMMARY REPORT   "
               "                                                   "
            << std::endl;
  std::cout << "==============================================================="
               "==================================================="
            << std::endl;
  std::cout << "| " << std::left << std::setw(6) << "Dtype"
            << "| " << std::setw(6) << "M"
            << "| " << std::setw(6) << "N"
            << "| " << std::setw(6) << "K"
            << "| " << std::setw(18) << "Winner Config"
            << "| " << std::setw(8) << "Time(ms)"
            << "| " << std::setw(10) << "Cycles"
            << "| " << std::setw(8) << "TFLOPS"
            << "| " << std::setw(8) << "MFU(%)"
            << "| " << std::setw(8) << "HBM(%)"
            << "| " << std::setw(8) << "Waves"
            << " |" << std::endl;
  std::cout << "|-------+-------+-------+-------+-------------------+----------"
               "+-------"
               "---+--------+--------+--------+--------|"
            << std::endl;

  for (const auto &r : summary) {
    std::cout << "| " << std::left << std::setw(6) << r.dtype << "| "
              << std::setw(6) << r.m << "| " << std::setw(6) << r.n << "| "
              << std::setw(6) << r.k << "| \033[32m" << std::setw(18)
              << r.best_run.name << "\033[0m"
              << "| " << std::setw(8) << std::fixed << std::setprecision(3)
              << r.best_run.time_ms << "| " << std::setw(10)
              << r.best_run.cycles << "| " << std::setw(8)
              << std::setprecision(2) << r.best_run.tflops << "| "
              << std::setw(8) << r.best_run.mfu << "| " << std::setw(8)
              << r.best_run.hbm_eff << "| " << std::setw(8)
              << r.best_run.grid_util << " |" << std::endl;
  }
  std::cout << "==============================================================="
               "==================================================="
            << std::endl;

  cudaFree(d_A);
  cudaFree(d_B);
  cudaFree(d_C);
  return 0;
}